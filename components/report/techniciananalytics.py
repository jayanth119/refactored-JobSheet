
import sys 
import os 
import pandas as pd 
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import plotly.express as px

def validate_numeric_data(df, numeric_columns):
    """Ensure specified columns are numeric, converting if necessary"""
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    return df
def technician_analytics(conn, start_date_str, end_date_str, user):
    """Technician-specific analytics - their work performance and device specialization"""
    
    st.markdown(f"### 🔧 Technician Performance - {user.get('full_name', 'Your Profile')}")
    
    # Technician sees only their assigned work
    where_clause = """
        j.created_at BETWEEN ? AND ? 
        AND EXISTS (
            SELECT 1 FROM technician_assignments ta 
            JOIN assignment_jobs aj ON ta.id = aj.assignment_id 
            WHERE aj.job_id = j.id AND ta.technician_id = ?
        )
    """
    params = [start_date_str, end_date_str, user['id']]
    
    # Create technician-specific tabs
    tab1, tab2, tab3 = st.tabs([
        "📈 My Performance", 
        "📱 Device Specialization", 
        "⏱️ Work Efficiency"
    ])
    
    with tab1:
        technician_performance(conn, where_clause, params, user['id'])
    
    with tab2:
        device_specialization(conn, where_clause, params, user['id'])
    
    with tab3:
        work_efficiency(conn, where_clause, params, user['id'])


def device_specialization(conn, where_clause, params, technician_id):
    """Technician's device specialization and expertise analysis"""
    
    device_expertise_query = f"""
        SELECT 
            j.device_type,
            j.device_model,
            COUNT(*) as jobs_handled,
            SUM(CASE WHEN j.status = 'Completed' THEN 1 ELSE 0 END) as completed_jobs,
            AVG(CASE WHEN j.status = 'Completed' THEN j.actual_cost ELSE NULL END) as avg_revenue_per_job,
            SUM(CASE WHEN j.status = 'Completed' THEN j.actual_cost ELSE 0 END) as total_revenue_generated
        FROM jobs j
        JOIN assignment_jobs aj ON j.id = aj.job_id
        JOIN technician_assignments ta ON aj.assignment_id = ta.id
        WHERE ta.technician_id = ? AND j.created_at BETWEEN ? AND ?
        GROUP BY j.device_type, j.device_model
        ORDER BY jobs_handled DESC
    """
    
    device_data = pd.read_sql(device_expertise_query, conn, 
                             params=[technician_id, params[0], params[1]])
    device_data = validate_numeric_data(device_data, ['jobs_handled', 'completed_jobs', 'avg_revenue_per_job', 'total_revenue_generated'])
    
    if not device_data.empty:
        col1, col2 = st.columns(2)
        
        with col1:
            try:
                # Device type distribution
                device_type_summary = device_data.groupby('device_type').agg({
                    'jobs_handled': 'sum',
                    'total_revenue_generated': 'sum'
                }).reset_index()
                
                fig = px.pie(device_type_summary, values='jobs_handled', names='device_type',
                            title="Jobs by Device Type")
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"Error creating device type pie chart: {str(e)}")
        
        with col2:
            try:
                # Revenue by device type
                fig = px.bar(device_type_summary, x='device_type', y='total_revenue_generated',
                            title="Revenue Generated by Device Type", color='total_revenue_generated')
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"Error creating revenue by device chart: {str(e)}")
        
        # Specialization insights
        st.markdown("#### Your Device Specialization")
        device_data['completion_rate'] = (device_data['completed_jobs'] / device_data['jobs_handled'] * 100).round(1)
        device_data['avg_revenue_per_job'] = device_data['avg_revenue_per_job'].round(2)
        
        st.dataframe(device_data[['device_type', 'device_model', 'jobs_handled', 
                                 'completed_jobs', 'completion_rate', 'avg_revenue_per_job']])
        
        # Top expertise areas
        top_devices = device_data.nlargest(5, 'jobs_handled')
        st.markdown("#### Your Top 5 Device Expertise Areas")
        for _, row in top_devices.iterrows():
            st.success(f"🔧 **{row['device_type']} - {row['device_model']}**: {row['jobs_handled']} jobs handled "
                      f"({row['completion_rate']:.1f}% completion rate)")



def work_efficiency(conn, where_clause, params, technician_id):
    """Technician work efficiency and productivity metrics"""
    
    # Work efficiency metrics
    efficiency_query = f"""
        SELECT 
            COUNT(*) as total_assignments,
            SUM(CASE WHEN ta.status = 'completed' THEN 1 ELSE 0 END) as completed_assignments,
            AVG(CASE 
                WHEN ta.completed_at IS NOT NULL AND ta.started_at IS NOT NULL 
                THEN (julianday(ta.completed_at) - julianday(ta.started_at)) * 24 
                ELSE NULL 
            END) as avg_hours_per_assignment,
            SUM(CASE WHEN j.status = 'Completed' THEN j.actual_cost ELSE 0 END) as total_revenue_generated
        FROM technician_assignments ta
        JOIN assignment_jobs aj ON ta.id = aj.assignment_id
        JOIN jobs j ON aj.job_id = j.id
        WHERE ta.technician_id = ? AND ta.assigned_at BETWEEN ? AND ?
    """
    
    efficiency_data = pd.read_sql(efficiency_query, conn, 
                                 params=[technician_id, params[0], params[1]]).iloc[0]
    efficiency_data = validate_numeric_data(pd.DataFrame([efficiency_data]), efficiency_data.keys()).iloc[0]
    
    # Display efficiency metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Assignments", f"{efficiency_data['total_assignments']:,}")
    
    with col2:
        completion_rate = (efficiency_data['completed_assignments'] / efficiency_data['total_assignments'] * 100) if efficiency_data['total_assignments'] > 0 else 0
        st.metric("Assignment Completion Rate", f"{completion_rate:.1f}%")
    
    with col3:
        avg_hours = efficiency_data['avg_hours_per_assignment'] if efficiency_data['avg_hours_per_assignment'] else 0
        st.metric("Avg. Hours per Assignment", f"{avg_hours:.1f}h")
    
    with col4:
        revenue = efficiency_data['total_revenue_generated'] if efficiency_data['total_revenue_generated'] else 0
        st.metric("Revenue Generated", f"₹{revenue:,.2f}")
    
    # Daily productivity trend
    daily_productivity_query = f"""
        SELECT 
            strftime('%Y-%m-%d', ta.assigned_at) as date,
            COUNT(*) as assignments_received,
            SUM(CASE WHEN ta.status = 'completed' THEN 1 ELSE 0 END) as assignments_completed,
            SUM(CASE WHEN j.status = 'Completed' THEN j.actual_cost ELSE 0 END) as daily_revenue
        FROM technician_assignments ta
        JOIN assignment_jobs aj ON ta.id = aj.assignment_id
        JOIN jobs j ON aj.job_id = j.id
        WHERE ta.technician_id = ? AND ta.assigned_at BETWEEN ? AND ?
        GROUP BY strftime('%Y-%m-%d', ta.assigned_at)
        ORDER BY date
    """
    
    productivity_data = pd.read_sql(daily_productivity_query, conn, 
                                   params=[technician_id, params[0], params[1]])
    productivity_data = validate_numeric_data(productivity_data, ['assignments_received', 'assignments_completed', 'daily_revenue'])
    
    if not productivity_data.empty:
        st.markdown("#### Daily Productivity Trend")
        try:
            fig = make_subplots(specs=[[{"secondary_y": True}]])
            
            fig.add_trace(
                go.Bar(x=productivity_data['date'], y=productivity_data['assignments_completed'],
                       name="Assignments Completed", opacity=0.7),
                secondary_y=False,
            )
            
            fig.add_trace(
                go.Scatter(x=productivity_data['date'], y=productivity_data['daily_revenue'],
                          mode='lines+markers', name="Daily Revenue", line=dict(color='red')),
                secondary_y=True,
            )
            
            fig.update_xaxes(title_text="Date")
            fig.update_yaxes(title_text="Assignments Completed", secondary_y=False)
            fig.update_yaxes(title_text="Revenue (₹)", secondary_y=True)
            
            st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.error(f"Error creating productivity chart: {str(e)}")

def technician_performance(conn, where_clause, params, user_id):
    """
    Retrieve technician performance metrics based on jobs assigned to them.
    
    Args:
        conn: Database connection object
        where_clause: SQL WHERE clause for filtering jobs
        params: Parameters for the WHERE clause
        user_id: ID of the user requesting the data (for authorization)
    
    Returns:
        dict: Performance metrics and job data
    """
    cursor = conn.cursor()
    
    try:
        # Base query to get jobs with technician assignments
        base_query = f"""
            SELECT 
                j.id,
                j.customer_id,
                j.device_type,
                j.device_model,
                j.problem_description,
                j.estimated_cost,
                j.raw_cost,
                j.actual_cost,
                j.status,
                j.created_at,
                j.updated_at,
                j.started_at,
                j.completed_at,
                c.name as customer_name,
                c.phone as customer_phone,
                u.full_name as technician_name,
                u.id as technician_id,
                ta.assigned_at,
                ta.started_at as assignment_started_at,
                ta.completed_at as assignment_completed_at,
                s.name as store_name
            FROM jobs j
            JOIN customers c ON j.customer_id = c.id
            JOIN assignment_jobs aj ON j.id = aj.job_id
            JOIN technician_assignments ta ON aj.assignment_id = ta.id
            JOIN users u ON ta.technician_id = u.id
            LEFT JOIN stores s ON j.store_id = s.id
            WHERE {where_clause}
            ORDER BY j.created_at DESC
        """
        
        cursor.execute(base_query, params)
        jobs = cursor.fetchall()
        
        # Convert to list of dictionaries for easier processing
        job_list = []
        for job in jobs:
            job_dict = {
                'id': job[0],
                'customer_id': job[1],
                'device_type': job[2],
                'device_model': job[3],
                'problem_description': job[4],
                'estimated_cost': job[5] or 0,
                'raw_cost': job[6] or 0,
                'actual_cost': job[7] or 0,
                'status': job[8],
                'created_at': job[9],
                'updated_at': job[10],
                'started_at': job[11],
                'completed_at': job[12],
                'customer_name': job[13],
                'customer_phone': job[14],
                'technician_name': job[15],
                'technician_id': job[16],
                'assigned_at': job[17],
                'assignment_started_at': job[18],
                'assignment_completed_at': job[19],
                'store_name': job[20]
            }
            job_list.append(job_dict)
        
        # Calculate performance metrics
        total_jobs = len(job_list)
        completed_jobs = len([j for j in job_list if j['status'] == 'Completed'])
        in_progress_jobs = len([j for j in job_list if j['status'] == 'In Progress'])
        pending_jobs = len([j for j in job_list if j['status'] in ['New', 'Assigned']])
        
        # Revenue metrics
        total_estimated_revenue = sum(j['estimated_cost'] for j in job_list)
        total_actual_revenue = sum(j['actual_cost'] for j in job_list if j['actual_cost'])
        
        # Completion rate
        completion_rate = (completed_jobs / total_jobs * 100) if total_jobs > 0 else 0
        
        # Average job duration (for completed jobs)
        completed_with_times = [
            j for j in job_list 
            if j['completed_at'] and j['started_at'] and j['status'] == 'Completed'
        ]
        
        avg_completion_time = None
        if completed_with_times:
            from datetime import datetime
            total_duration = 0
            for job in completed_with_times:
                start = datetime.fromisoformat(job['started_at'].replace('Z', '+00:00'))
                end = datetime.fromisoformat(job['completed_at'].replace('Z', '+00:00'))
                duration = (end - start).total_seconds() / 3600  # Convert to hours
                total_duration += duration
            avg_completion_time = total_duration / len(completed_with_times)
        
        # Group by technician for individual performance
        technician_stats = {}
        for job in job_list:
            tech_id = job['technician_id']
            tech_name = job['technician_name']
            
            if tech_id not in technician_stats:
                technician_stats[tech_id] = {
                    'name': tech_name,
                    'total_jobs': 0,
                    'completed_jobs': 0,
                    'in_progress_jobs': 0,
                    'pending_jobs': 0,
                    'total_revenue': 0,
                    'estimated_revenue': 0
                }
            
            stats = technician_stats[tech_id]
            stats['total_jobs'] += 1
            stats['estimated_revenue'] += job['estimated_cost']
            stats['total_revenue'] += job['actual_cost'] or 0
            
            if job['status'] == 'Completed':
                stats['completed_jobs'] += 1
            elif job['status'] == 'In Progress':
                stats['in_progress_jobs'] += 1
            else:
                stats['pending_jobs'] += 1
        
        # Calculate completion rates for each technician
        for tech_id in technician_stats:
            stats = technician_stats[tech_id]
            stats['completion_rate'] = (
                (stats['completed_jobs'] / stats['total_jobs'] * 100) 
                if stats['total_jobs'] > 0 else 0
            )
        
        # Get recent job notes for context
        recent_job_ids = [str(j['id']) for j in job_list[:10]]  # Last 10 jobs
        notes_query = f"""
            SELECT jn.job_id, jn.note, jn.created_at
            FROM job_notes jn
            WHERE jn.job_id IN ({','.join(['?'] * len(recent_job_ids))})
            ORDER BY jn.created_at DESC
            LIMIT 20
        """
        
        cursor.execute(notes_query, recent_job_ids)
        notes = cursor.fetchall()
        
        job_notes = {}
        for note in notes:
            job_id = note[0]
            if job_id not in job_notes:
                job_notes[job_id] = []
            job_notes[job_id].append({
                'note': note[1],
                'created_at': note[2]
            })
        
        return {
            'summary': {
                'total_jobs': total_jobs,
                'completed_jobs': completed_jobs,
                'in_progress_jobs': in_progress_jobs,
                'pending_jobs': pending_jobs,
                'completion_rate': round(completion_rate, 2),
                'total_estimated_revenue': round(total_estimated_revenue, 2),
                'total_actual_revenue': round(total_actual_revenue, 2),
                'avg_completion_time_hours': round(avg_completion_time, 2) if avg_completion_time else None
            },
            'technician_performance': technician_stats,
            'jobs': job_list,
            'recent_notes': job_notes,
            'request_user_id': user_id
        }
        
    except Exception as e:
        # Log the error (you might want to use proper logging)
        print(f"Error in technician_performance: {str(e)}")
        return {
            'error': str(e),
            'summary': {
                'total_jobs': 0,
                'completed_jobs': 0,
                'in_progress_jobs': 0,
                'pending_jobs': 0,
                'completion_rate': 0,
                'total_estimated_revenue': 0,
                'total_actual_revenue': 0,
                'avg_completion_time_hours': None
            },
            'technician_performance': {},
            'jobs': [],
            'recent_notes': {},
            'request_user_id': user_id
        }
    
    finally:
        cursor.close()